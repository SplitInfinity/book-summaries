# The Righteous Mind

## Part I: Intuitions Come First, Strategic Reasoning Second
*Central Metaphor:* The mind is divided, like a rider on an elephant, and the rider’s job is to serve the elephant.

### Where Does Morality Come From?
Where does morality come from? The two most common answers have long been that it is innate (the nativist answer) or that it comes from childhood learning (the empiricist answer). In this chapter I considered a third possibility, the rationalist answer, which dominated moral psychology when I entered the field: that morality is self-constructed by children on the basis of their experiences with harm. Kids know that harm is wrong because they hate to be harmed, and they gradually come to see that it is therefore wrong to harm others, which leads them to understand fairness and eventually justice. I explained why I came to reject this answer after conducting research in Brazil and the United States. I concluded instead that:

- The moral domain varies by culture. It is unusually narrow in Western, educated, and individualistic cultures. Sociocentric cultures broaden the moral domain to encompass and regulate more aspects of life.
- People sometimes have gut feelings–particularly about disgust and disrespect–that can drive their reasoning. Moral reasoning is sometimes a post hoc fabrication.
- Morality can’t be entirely self-constructed by children based on their growing understanding of harm. Cultural learning of guidance must play a larger large than rationalist theories had given it.

If morality doesn’t come primarily from reasoning, then that leaves some combination of innateness and social learning as the most likely candidates. In the rest of this book I’ll try to explain how morality can be innate (as a set of evolved intuitions) and learned (as children learn to apply those intuitions within a particular culture). We’re born to be righteous, but we have to learn, what, exactly, people like us should be righteous about.

### The Intuitive Dog and Its Rational Tail
People reason and people have moral intuitions (including moral emotions), but what is the relationship among these processes? Plato believed that reason could and should be the master; Jefferson believed that the two processes were equal partners (head and heart) ruling a divided empire; Hume believed that reason was (and was only fit to be) the servant of the passions. In this chapter I tried to show that Hume was right:

- The mind is divided into parts, like a rider (controlled processes) on an elephant (automatic processes). The rider evolved to serve the elephant.
- You can see the rider serving the elephant when people are morally dumbfounded. They have strong gut feelings about what is right and wrong, and they struggle to construct post hoc justifications for those feelings. Even when the servant (reasoning) comes back empty-handed, the master (intuition) doesn’t change his judgement.
- The social intuitionist model starts with Hume’s model and makes it more social. Moral reasoning is part of our lifelong struggle to win friends and influence people. That’s why I say that “intuitions come first, strategic reasoning second.” You’ll misunderstand moral reasoning if you think about it as something people do by themselves in order to figure out the truth.
- Therefore, if you want to change someone’s mind about a moral or political issue, *talk to the elephant first.* If you ask people to believe something that violates their intuitions, they will devote their efforts to finding an escape hatch–a reason to doubt your argument or conclusion. They will almost always succeed.

I have tried to use intuitionism while writing this book. My goal is to change the wya a diverse group of readers–liberal and conservative, secular and religious–think about morality, politics, religion, and each other. I knew that I had to take things slowly and address myself more to elephants than to riders. I couldn’t just lay out the theory in chapter 1 and then ask readers to reserve judgement until I had presented all of the supporting evidence. Rather, I decided to weave together the history of moral psychology and my own personal story to create a sense of movement from rationalism to intuitionism. I threw in historical anecdotes, quotations from the ancients, and praise for a few visionaries. I set up metaphors (such as the rider and the elephant) that will recur throughout the book. I did these things in order to “tune up” your intuitions about moral psychology. If I have failed and you have a visceral dislike of intuitionism or of me, then no amount of evidence I could present will convince you that intuitionism is correct. But if you now feel an intuitive sense that intuitionism might be true, then let’s keep going. In the next two chapters I’ll address myself more to riders than to elephants.

### Elephants Rule
The first principle of moral psychology is *intuitions come first, strategic reasoning comes second.* Ins support of this principle, I reviewed six areas of experimental research demonstrating that:

- Brains evaluate instantly and constantly (as Wundt and Zajonc said).
- Social and political judgements depend heavily on quick intuitive lashes (as Todorov and work with the IAT have shown).
- Our bodily states sometimes influence our moral judgements. Bad smells and tastes can make people more judgmental (as can anything that makes people think about purity and cleanliness). 
- Psychopaths reason but don’t feel (and are severely deficient morally).
- Babies feel but don’t reason (and have the beginnings of morality).
- Affective reactions are in the right place at the right time in the brain (as shown by Damasio, Greene, and a wave of more recent studies).

Putting all six together gives us a pretty clear portrait of the rider and the elephant, and the roles they play in our righteous minds. The elephant (automatic processes) is where most of the action is in moral psychology. Reasoning matters, of course, particularly between people, and particularly when reasons trigger new intuitions. Elephants rule, but they are neither dumb nor despotic. Intuitions can be shaped by reasoning, especially when reasons are embedded in a friendly conversation or an emotionally compelling novel, movie, or news story.

But the bottom line is that when we see or hear about the things other people do, the elephant begins to lean immediately. The rider, who is always trying to anticipate the elephant’s next move, begins looking around for a way to support such a move. When my Wie reprimanded me or leaving dirty dishes on the counter, I honestly believed that I was innocent. I sent my reasoning forth to defend me and it came back with an effective legal brief in just three seconds. It’s only because I happened–at that very moment–to be writing about the nature of moral reasoning that I bothered to look closely at my lawyer’s arguments and found them to be historical fictions, based only loosely on real events.

Why do we have this weird mental architecture? As hominid brains tripled in size over the last 5 million years, developing a language and a vastly improved ability to reason, why did we evolve an inner lawyer, rather than an inner judge or scientist? Wouldn’t it have been most adaptive for our ancestors to figure out the *truth,* the real truth about who did what and why, rather than using all that brainpower just to find evidence in support of what they wanted to believe? That depends on which you think was more important for our ancestors’ survival: truth or reputation.

### Vote for Me (Here’s Why)
The first principle of moral psychology is *intuitions come first, strategic reasoning second.* To demonstrate the strategic functions of moral reasoning, I reviewed five areas of research showing that moral thinking is more like a politician searching for votes than a scientist searching for truth:

- We are obsessively concerned about what others think of us, although much of the concern is unconscious and invisible to us.
- Conscious reasoning functions like a press secretary who automatically justifies any position taken by the president.
- With the help of our press secretary, we are able to lie and cheat often, and then cover it up so effectively that we convince even ourselves.
- Reasoning can take us to almost any conclusion we want to reach, because we ask “Can I believe it?” when we want to believe something, but “Must I believe it?” when we don’t want to believe. The answer is almost always yes to the first question and no to the second.
- In moral and political matters we are often groups, rather than selfish. We deploy our reasoning skills to support our team, and to demonstrate commitment to our team.

I concluded by warning that the worship of reason, which is sometimes found in philosophical and scientific circles, is a delusion. It is an example of faith in something that does not exist. I urged instead a more intuitionist approach to amorality and moral education, one that is more humble about the abilities of individuals, and more attuned to the contexts and social systems that enable people to think and act well.

I have tried to make a reasoned case that our moral capacities are best described from an intuitionist perspective. I do not claim to have examined the question from all sides, nor to have offered irrefutable proof. Because of the insurmountable power of the confirmation bias, counterarguments will have to be produced by those who disagree with me. Eventually, if the scientific community works as it is supposed to, the truth will emerge as a large number of flawed and limited minds battle it out.

---

This concludes Part I of this book, which was about the first principle of moral psychology: *intuitions come first, strategic reasoning second.* To explain this principle, I used the metaphor of the mind as a rider (reasoning) on an elephant (intuition), and I said that the rider’s function si to serve the elephant. Reasoning matters, particularly because reasons do sometimes influence other people, but most of the action in moral psychology is in the intuitions. In Part II I’ll get much more specific about what those intuitions are and where they came from. I’ll draw a map of moral space, and I’ll show why that map is more favorable to conservative politicians than to liberals.

## Part II: There’s More to Morality than Harm and Fairness
*Central Metaphor:* The righteous mind is like a tongue with six taste receptors.

### Beyond WEIRD Morality
The second principle of moral psychology is: *there’s more to morality than harm and fairness.* In support of this claim I described research showing that people who grow up in Western, education, industrial, rich, and democratic (WEIRD) societies are statistical outliers on many psychological measures, including measures of moral psychology. I also showed that:

- The WEIRDer you are, the more you perceive a world full of separate objects, rather than relationships.
- Moral pluralism is true descriptively. As a simple matter of anthropological fact, the moral domain varies across cultures.
- The moral domain is unusually narrow in WEIRD cultures, where it is largely limited to the ethic of autonomy (i.e., moral concerns about individuals harming, oppressing, or cheating other individuals). It is broader–including the ethics of community and divinity–in most other societies, and within religious and conservative moral matrices within WEIRD societies.
- Moral matrices bind people together and blind them to the coherence, or even existence, of other matrices. This makes it very difficult for people to consider the possibility that there might really be more than one form of moral truth, or more than one valid framework for judging people or running a society.

In the next three chapters I’ll catalogue the moral intuitions, showing exactly what else there is beyond harm and fairness. I’ll show how a small set of innate and universal moral foundations can be used to construct a great variety of moral matrices. I’ll offer tools you can use to understand moral arguments emanating from matrices that are not your own.

### Taste Buds of the Righteous Mind
The second principle of moral psychology is: *there’s more to morality than harm and fairness.* In this chapter I began to say exactly what more there is:

- Morality is like taste in many ways–an analogy made long ago by Hume and Mencius.
- Deontology and utilitarianism are “one-receptor” moralities that are likely to appear most strongly to people who are high on systemizing and low on empathizing.
- Hume’s pluralist, sentimentalist, and naturalist approach to ethics is more promising than utilitarianism or deontology for modern moral psychology. As a first step in resuming Hume’s project, we should try to identify the taste receptors of the righteous mind.
- Modularity can help us think about innate receptors, and how they produce a variety of initial perceptions that get developed in culturally variable ways.
- **Five good candidates for being taste receptors of the righteous mind are care, fairness, loyalty, authority and sanctity.**

In psychology, theories are cheap. Anyone can invent one. Progress happens when theories are tested, supported, and corrected by empirical evidence, especially when a theory proves to be useful–for example, if it helps people to understand why half of the people in their country seem to live in a different moral universe. That’s what happened next.

### The Moral Foundations of Politics
I began this chapter by trying to trigger your intuitions about the five moral foundations that I introduced in chapter 6. I then defined innateness as “organized in advance of experience,” like the first draft of a book that gets revised as individuals grow up within diverse cultures. This definition allowed me to propose that the moral foundations are innate. Particular rules and virtues vary across cultures, so you’ll get fooled if you look for universality in finished books. You won’t find a single paragraph that exists in identical form in every human culture. But if you look for links between evolutionary theory and anthropological observations, you can take some educated guesses about what was in the universal first draft of human nature. I tried to make (and justify) five such guesses:

- The **Care/Harm** foundation evolved in response to the adaptive challenge of caring for vulnerable children. It makes us sensitive to signs of suffering and need; it makes us despise cruelty and want to care for those who are suffering.
- The **Fairness/Cheating** foundation evolved in response to the adaptive challenge of reaping the rewards of cooperation without getting exploited. It make sus sensitive to indications that another person is likely to be a good (or bad) partner or collaboration and reciprocal altruism. It makes us want to shun or punish cheaters.
- The **Loyalty/Betrayal** foundation evolved in response to the adaptive challenge of forming and maintaining coalitions. It makes us sensitive to signs that another person is (or is not) a team player. It makes us trust and reward such people, and it makes us want to hurt, ostracize, or even kill those who betray us or our group.
- The **Authority/Subversion** foundation evolved in response to the adaptive challenge of forging relationships that will benefit us within social hierarchies. It makes us sensitive to signs of rank or status, and to signs that other people are (or are not) behaving properly, given their position.
- The **Sanctity/Degradation** foundation evolved initially in response to the adaptive challenge of the omnivore’s dilemma, and then to the broader challenge of living in a world of pathogens and parasites. It includes the behavioural immune system, which can make us wary of a diverse array of symbolic objects and threats. It makes it possible for people to invest objects with irrational and extreme values–both positive and negative–which are important for binding groups together.

I showed how the two ends of the political spectrum rely upon each foundation in different ways, or to different degrees. It appears that the left relies primarily on the Care and Fairness foundations, whereas the right uses all five. If this is true, does left-wing morality activate just one or two taste receptors, whereas right-wing morality engages a broader palate, including loyalty, authority, and sanctity? And if so, does that give conservative politicians a broader variety of ways to connect with voters?

### The Conservative Advantage
Moral psychology can help to explain why the Democratic Party has had so much difficulty connecting with voters since 1980. Republicans understand the social intuitionist model better than do Democrats. Republicans speak more directly to the elephant. They also have a better grasp of Moral Foundations Theory; they trigger every single taste receptor.

I presented the Durkhemian vision of society, favoured by social conservatives, in which the basic social unit is the family, rather than the individual, and in which order, hierarchy and tradition are highly valued. I contrasted this vision with the liberal Millian vision, which is more open and individualistic. I noted that a Million society has difficulty binding *pluribus* into *unum.* Democrats often pursue policies that leave them open to charges of treason, subversion, and sacrilege. 

I then described how my colleagues and I revised Moral Foundations Theory to do a better job of explaining intuitions about liberty and fairness:

- We added the **Liberty/Oppression** foundation, which makes people notice and resent any sign of attempted domination. It triggers an urge to band together to resist or overthrow bullies and tyrants. This foundation supports the egalitarianism and antiauthoritarianism of the left, as well as the don’t-tread-on-me and give-me-liberty antigovernment anger of libertarians and some conservatives.
- We modified the **Fairness** foundation **to make it focus more strongly on proportionality.** The Fairness foundation begins with the psychology of reciprocal altruism, but its duties expanded once humans created gossiping and punitive moral communities. Most people have a deep intuitive concern for the law of karma–they want to see the cheaters punished and good citizens rewarded in proportion to their deeds.

With these revisions, Moral Foundations Theory can now explain one of the great puzzles that has preoccupied Democrats in recent years: why do rural and working-class Americans general vote Republican when it is the Democratic Party that wants to redistribute money more evenly?

Democrats often say that Republicans have duped these people into voting against their economic self-interest. That was the thesis of the popular 2004 book *What’s the Matter with Kansas?.*) But from the perspective of Moral Foundations Theory, rural and working-class voters were in fact voting for their moral interests. They don’t want their nation to devote itself primarily to the care of victims and the pursuit of social justice. Until Democrats understand the Durkhemian vision of society and the difference between a six-foundation morality and a three-foundation morality, they will not understand what makes people vote Republican.

---

In Part I of this book I presented the first principle of moral psychology: *intuitions come first, strategic reasoning second.* In Part II, I described those intuitions in detail while presenting the second principle: *there’s more to morality than harm or fairness.* Now we’re ready to examine how moral diversity can so easily divide good people into hostile groups that do not want to understand each other. We’re ready to move on to the third principle: *morality binds and blinds.*

## Part III: Morality Binds and Blinds
*Central Metaphor:* We are 90 percent chimp and 10 percent bee.

### Why Are We So Groupish?
Darwin believed that morality was an adaptation that evolved by natural selection operating at the individual level and at the group level. Tribes with more virtuous members replaced tribes with more selfish members. But Darwin’s idea was banished from the academic world when Williams and Dawkins argued that the free rider problem dooms group selection. The sciences then entered a three-decade period during which competition between groups was downplayed and everyone focused on competition among individuals within groups. Seemingly altruistic acts had to be explained as covert forms of selfishness.

But in recent years new scholarship has emerged that elevates the role of groups in evolutionary thinking. Natural selections works at multiple levels simultaneously, sometimes including groups of organisms. I can’t say for sure that human nature was shaped by group selection–there are scientists whose views I respect on both sides of the debate. But as a psychologist studying morality, I can say that multilevel selection would go a long way toward explaining why people are simultaneously so selfish and so groupish.

There is a great deal of new scholarship since the 1970s that compels us to think anew about group selection (as a part of multilevel selection). I organized that scholarship into four “exhibits” that collectively amount a a defense of group selection.

- *Exhibit A: Major transitions produce superorganisms.* The history of life on Earth shows repeated examples of “major transitions.” When the free rider problem Is muted at one level of the biological hierarchy, larger and more powerful vehicles (superorganisms) arise at the next level up in the hierarchy, with new properties such as a division of labour, cooperation, and altruism within the group.
- *Exhibit B: Shared intentionality generates moral matrices.* The Rubicon crossing that let our ancestors function so well in their groups was the emergence of the uniquely human ability to share intentions and other mental representations. This ability enabled early humans to collaborate, divide labor, and develop shared norms for judging each other’s behaviour. These shared norms were the beginning of the moral matrices that govern our social lives today.
- *Exhibit C: Genes and cultures coevolve.* Once our ancestors crossed the Rubicon and began to share intentions, our evolution become a two-stranded affair. People created new customs, norms, and institutions that altered the degree to which many groupish traits were adaptive. In particular, gene-culture coevolution gave us a set of tribal instincts; we love to mark group membership, and then we cooperate preferentially with members of our group.
- *Exhibit D: Evolution can be fast.* Human evolution did not stop or slow down 50 000 years ago. It sped up. Gene-culture coevolution reached a fever pitch during the last 12 000 years. We can’t just examine modern-day hunter-gatherers and assume that they represent universal human nature as it was locked into place 50 000 years ago. Periods of massive environmental change (as occurred between 70 000 and 140 000 years ago) and cultural change (as occurred during the Holocene era) should figure more prominently in our attempts to understand who we are, and how we got our righteous minds.

Most of human nature was shaped by natural selection operating at the level of the individual. Most, but not all. We have a few group-related adaptations too, as many Americans discovered in the days after 9/11. We humans have a dual nature–we are selfish primates who long to be a part of something larger than nobler than ourselves. We are 90 percent chimp and 10 percent bee. If you take that claim metaphorically, then the groupish and hivish things that people do will make a lot more sense. It’s almost as though there’s a switch in our heads that activates our hivish potential when conditions are just right.
 
### The Hive Switch
When I began writing *The Happiness Hypothesis*, I believed that happiness came from within, as Buddha and the Stoic philosophers said thousands of years ago. You’ll never make the world inform to your wishes, so focus on changing yourself and your desires. But by the time I finished writing, I had changed my mind: happiness comes from between. It comes from getting the right relationships between yourself and other, yourself and your work, and yourself and something larger than yourself.

Once you understand our dual nature, including our groupish overlay, you can see why happiness comes from between. We evolved to live in groups. Our minds were designed not only to help us win the competition within our groups, but also to help us unite with those in our group to win competitions across groups. 

In this chapter, I presented the hive hypothesis, which states that human beings are conditional hive creatures. We have the ability (under special circumstances) to transcend self-interest and lose ourselves (temporarily and ecstatically) in something larger than ourselves. I called this ability the hive switch. The hive switch is another of stating Durkheim’s idea that we are *Homo duplex*; we live most of our lives in the ordinary (profane) world, but we achieve our greatest joys in those brief moments of transit to the sacred world, in which we become “simple part of a whole.”

I described three common ways in which people flip the hive switch: awe in nature, Durkheimian drugs, and raves. I described recent findings about oxytocin and mirror neurons that suggest that they are the stuff of which the hive switch is made. Oxytocin bonds people to their groups, not to all of humanity. Mirror neurons help people empathize with others, but particularly those that share their moral matrix.

It would be nice to believe that we humans we designed to love everyone unconditionally. Nice, but rather unlikely from an evolutionary perspective. Parochial love–love within groups–amplified by similarity, a sense of shared fate, and the suppression of free riders, may be the most we can accomplish.

### Religion is a Team Sport
If you think about religion as a set of beliefs about supernatural agents, you’re bound to misunderstand it. You’ll see those beliefs as foolish delusions, perhaps even as parasites that exploit our brains for their own benefit. But if you take a Durkheimian approach to religion (focusing on belonging) and a Darwinian approach to morality (involving multilevel selection), you get a very different picture. You see that religious practices have been binding our ancestors into groups for tens of thousands of years. That binding usually involves some blinding–once any person, book, or principle is declared sacred, then devotees can no longer question it or think clearly about it.

Our ability to believe in supernatural agents may well have begun as an accidental by-product of a hypersensitive agency detection device, but once early humans began believing in such agents, the groups that used them to construct moral communities were the ones that lasted and prospered. Like those nineteenth-century religious communes, they used their gods to elicit sacrifice and commitment from members. Like those subjects in the cheating studies and trust games, their gods helped them to suppress cheating and increase trustworthiness. Only groups that elicit commitment and suppress free riding can grow.

This is why human civilization grew so rapidly after the first plants and animals were domesticated. Religions and righteous minds had been coevolving, culturally and genetically, for tens of thousands of years before the Holocene era, and both kinds of evolution sped up when agriculture presented new challenges and opportunities. Only groups whose gods promoted cooperation, and whose individual minds responded to those gods, were ready to rise to these challenges and reap the rewards. 

We humans have an extraordinary capability to care about things beyond ourselves, to circle around those things with other people, and in the process to bind ourselves into teams that can pursue larger projects. That’s what religion is all about. And with a few adjustments, it’s what politics is about too. In the final chapter we’ll take one last look at political psychology. We’ll try to figure out why people choose to bind themselves into one political team or another. And we’ll look especially at how team membership blinds people to the motives and morals of their opponents–and to the wisdom that is to be found scattered among diverse political ideologies.

### Can’t We All Disagree More Constructively?
People don’t adopt their ideologies at random, or by soaking up whatever ideas are around them. People whose genes gave them brains that get a special pleasure from novelty, variety, and diversity, while simultaneously being less sensitive to sings of threat, are predisposed (but not predestined) to become liberals. They tend to develop certain “characteristic adaptations” and “life narratives” that make them resonate–unconsciously and intuitively–with the grand narratives told by the political movements on the left (such as the liberal progress narrative). People whose genes give them brains with the opposite settings are predisposed, for the same reasons, to resonate with the grand narratives of the right (such as the Reagan narrative).

Once people join a political team, they get ensnared in its moral matrix. They see confirmation of their grand narrative everywhere and it’s difficult–perhaps impossible–to convince them that they are wrong if you argue with them from outside of their matrix. I suggested that liberals often have difficulty understanding how the Loyalty, Authority, and Sanctity foundations have anything to do with morality. In particular, liberals often have difficulty seeing moral capital, which I defined as the resources that sustain a moral community.

I suggested that liberals and conservatives are like yin and yang–both are “necessary elements of a healthy of state of political life,” as John Stuart Mill put it. Liberals are experts in care; they are better able to see the victims of existing social arrangements, and they continually push us to update those arrangements and invest new ones. As Robert F. Kennedy said: “There are those that look at things the way they are, and ask why? I dream of things that never were, and ask why not?” I showed how this moral matrix leads liberals to make two points that are (in my opinion) profoundly important for the health of a society: (1) governments can and should restrain corporate superorganisms, and (2) some big problems really can be solved by regulation.

I explained how libertarians (who sacralize liberty) and social conservatives (who sacralize certain institutions and traditions) provide a crucial counterweight to the liberal reform movements that have been so influential in America and Europe since the early twentieth century. I said that libertarians are right that markets are miraculous (at least when their externalities and other failures can be addressed), and I said that social conservatives are right that you don’t usually help the bees by destroying the hive. 

Finally, I said that the increasing Manichaeism of American political life is not something we can address by signing pledges and resolving to be nicer. Our politics will become more civil when we find ways to change the procedures for electing politicians and the institutions and environments within which they interact.

---

Morality binds and blinds. It binds us into ideological teams that fight each other as though the fate of the world depended on our side winning each battle. It blinds us to the fact that each team is composed of good people who have something important to say.
